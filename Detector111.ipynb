{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from commonfunctions import *\n",
    "import cv2  as cv\n",
    "import imutils\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from joblib import load\n",
    "\n",
    "from skimage.filters import threshold_local\n",
    "from skimage import measure\n",
    "from skimage.feature import hog\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_contour_distance(contour1, contour2): # \n",
    "    x1, y1, w1, h1 = cv.boundingRect(contour1)\n",
    "    c_x1 = x1 + w1\n",
    "    c_y1 = y1 + h1/2\n",
    "\n",
    "    x2, y2, w2, h2 = cv.boundingRect(contour2)\n",
    "    c_x2 = x2 \n",
    "    c_y2 = y2 + h2/2\n",
    "    \n",
    "    if c_x1 > c_x2:\n",
    "        c_x1 = x1\n",
    "        c_x2 = x2 + w2\n",
    "\n",
    "    \n",
    "    return (abs(c_x1 - c_x2) , abs(c_y1 - c_y2))\n",
    "\n",
    "def merge_contours(contour1, contour2):\n",
    "    return np.concatenate((contour1, contour2), axis=0)\n",
    "\n",
    "def calculate_distance_y(contour1, contour2):\n",
    "    x1, y1, w1, h1 = cv.boundingRect(contour1)\n",
    "    c_x1 = x1 + w1/2\n",
    "    c_y1 = y1 + h1\n",
    "\n",
    "    x2, y2, w2, h2 = cv.boundingRect(contour2)\n",
    "    c_x2 = x2 + w2/2\n",
    "    c_y2 = y2\n",
    "    \n",
    "    if c_y1 > c_y2:\n",
    "        c_y1 = y1\n",
    "        c_y2 = y2 + h2\n",
    "\n",
    "    return (abs(c_x1 - c_x2) , abs(c_y1 - c_y2))\n",
    "\n",
    "def agglomerative_cluster(contours, threshold_distance=20):\n",
    "    current_contours = contours\n",
    "    while len(current_contours) > 1:\n",
    "        min_distance = None\n",
    "        min_coordinate = None\n",
    "        \n",
    "        for x in range(len(current_contours)-1):\n",
    "            for y in range(x+1, len(current_contours)):\n",
    "                distancex,distancey = calculate_contour_distance(current_contours[x], current_contours[y])\n",
    "                if min_distance is None and distancey <= 25:\n",
    "                    min_distance = distancex\n",
    "                    min_coordinate = (x, y)\n",
    "                elif  min_distance != None and distancex < min_distance and distancey <= 25:\n",
    "                    min_distance = distancex\n",
    "                    min_coordinate = (x, y)\n",
    "        \n",
    "        if  min_distance != None and min_distance < threshold_distance :\n",
    "            index1, index2 = min_coordinate\n",
    "            current_contours[index1] = merge_contours(current_contours[index1], current_contours[index2])\n",
    "            del current_contours[index2]\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return current_contours\n",
    "\n",
    "def agglomerative_cluster_y(contours, threshold_distance=5):\n",
    "    current_contours = contours\n",
    "    while len(current_contours) > 1:\n",
    "        min_distance = None\n",
    "        min_coordinate = None\n",
    "        \n",
    "        for x in range(len(current_contours)-1):\n",
    "            for y in range(x+1, len(current_contours)):\n",
    "                distancex,distancey = calculate_distance_y(current_contours[x], current_contours[y])\n",
    "                if min_distance is None and distancex <= 10:\n",
    "                    min_distance = distancey\n",
    "                    min_coordinate = (x, y)\n",
    "                elif  min_distance != None and distancey < min_distance and distancex <= 10:\n",
    "                    min_distance = distancey\n",
    "                    min_coordinate = (x, y)\n",
    "        \n",
    "        if min_distance != None and min_distance < threshold_distance:\n",
    "            index1, index2 = min_coordinate\n",
    "            current_contours[index1] = merge_contours(current_contours[index1], current_contours[index2])\n",
    "            del current_contours[index2]\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return current_contours\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def LPD(img):\n",
    "    # Step 1: Edge Detection\n",
    "    s= img.shape\n",
    "    img = imutils.resize(img, width = 1000 , height= 1000 * s[0] // s[1])\n",
    "    \n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "    gray = gray[gray.shape[0]*2//5:gray.shape[0],:]\n",
    "    gray = cv.GaussianBlur(gray, (3,3),0)\n",
    "    \n",
    "    img = img[img.shape[0]*2//5:img.shape[0],:]\n",
    "    \n",
    "    # The Black Hat operation is the difference between the closing and input image \n",
    "    \n",
    "    rectKern = cv.getStructuringElement(cv.MORPH_RECT, (7,5))\n",
    "    blackhat = cv.morphologyEx(gray, cv.MORPH_BLACKHAT, rectKern)\n",
    "    \n",
    "\n",
    "\n",
    "    img_thresh = blackhat\n",
    "    img_thresh[ img_thresh < 50 ] = 0\n",
    "    img_thresh[ img_thresh >= 50 ] = 255\n",
    "    \n",
    "    num_ones = np.count_nonzero(img_thresh == 255)\n",
    "    num_zeros = np.count_nonzero(img_thresh == 0)\n",
    "    ratio = round(num_ones / (num_zeros+num_ones),4)\n",
    "    \n",
    "    \n",
    "    sobel_x = cv.Sobel(img_thresh, cv.CV_64F, 1, 0, ksize=3)  # Gradient in x-direction\n",
    "    sobel_x = np.absolute(sobel_x)\n",
    "    maxVal = np.max(sobel_x)\n",
    "    sobel_x = 255 * ((sobel_x) / (maxVal))\n",
    "    sobel_x = sobel_x.astype(\"uint8\")\n",
    "    \n",
    "    restore_kern = cv.getStructuringElement(cv.MORPH_RECT, (2,2))\n",
    "    restored = sobel_x\n",
    "    if ratio < 0.0042:\n",
    "        restored = cv.dilate(sobel_x, None, iterations = 2)\n",
    "    \n",
    "    closeKern = cv.getStructuringElement(cv.MORPH_RECT, (7,7))\n",
    "    closed_image = cv.morphologyEx(restored, cv.MORPH_CLOSE, closeKern)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    eroded_1= cv.erode(closed_image, None, iterations = 2)\n",
    "    \n",
    "    dilated_1 = cv.dilate(eroded_1, None, iterations = 3)\n",
    "    \n",
    "    \n",
    "    eroded_2= cv.erode(dilated_1, None, iterations = 2)\n",
    "    dilated_2 = cv.dilate(eroded_2, None, iterations = 3)\n",
    "    \n",
    "    dilated_2[ dilated_2 < 140 ] = 0\n",
    "    dilated_2[ dilated_2 >= 140 ] = 255\n",
    "    \n",
    "    eroded_3 = cv.erode(dilated_2, None, iterations = 2)\n",
    "    # print(ratio)\n",
    "    if ratio >=0.01:\n",
    "        # print(\"*\"*100)\n",
    "        erodekern = cv.getStructuringElement(cv.MORPH_RECT, (3,3))\n",
    "        eroded_3 = cv.erode(eroded_3,erodekern,iterations = 2)\n",
    "        \n",
    "    dilated_3 = cv.dilate(eroded_3, None, iterations=8)\n",
    "    \n",
    "    vertical_kernel = cv.getStructuringElement(cv.MORPH_RECT, (5,1))\n",
    "    final_img = cv.dilate(dilated_3, vertical_kernel, iterations = 3)\n",
    "        \n",
    "    img1_thresh = final_img\n",
    "    \n",
    "    contours, hierarchy = cv.findContours(img1_thresh.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE) \n",
    "\n",
    "    merged_contours = []\n",
    "    copyContours = list(contours)\n",
    "    merged_contours = agglomerative_cluster(copyContours) # merge contours which is close together\n",
    "    \n",
    "    cnts = sorted(merged_contours, key=cv.contourArea, reverse=True)\n",
    "    \n",
    "    \n",
    "    img_cont = img.copy()\n",
    "    cv.drawContours(img_cont,cnts,-1, (0, 255, 0), 2)\n",
    "#     show_images([final_img])\n",
    "    cropped_image = img.copy()\n",
    "    for cnt in cnts:\n",
    "\n",
    "        area = cv.contourArea(cnt)\n",
    "        x1, y1, w1, h1 = cv.boundingRect(cnt)\n",
    "        c_x1 = x1 + w1/2\n",
    "        c_y1 = y1 + h1/2    \n",
    "        \n",
    "        if w1 > 300:\n",
    "            continue\n",
    "        if h1 >= 150:\n",
    "            continue\n",
    "        if 2200 < area < 17500: # filter on the area of the contours \n",
    "            peri = cv.arcLength(cnt, True)\n",
    "            approx = cv.approxPolyDP(cnt, 0.02 * peri, True)\n",
    "            x, y, w, h = cv.boundingRect(approx)\n",
    "            ar = w / float(h)\n",
    "            # print(f\"area:{area}\")\n",
    "            if (ar>=1.5 and ar<=6):\n",
    "                # print(f\"Ar:{ar}\")\n",
    "                if ( y == 0):\n",
    "                    cropped_image = img[y :y + h + 5, x:x + w]\n",
    "                else:\n",
    "                    cropped_image = img[y -6 :y + h + 5, x:x + w]\n",
    "#                 cv.drawContours(img,cnt,-1,(0,255,0),2)\n",
    "                \n",
    "                # show_images([img,cropped_image])\n",
    "                # show_images([cropped_image])\n",
    "                # print(cropped_image)\n",
    "                return cropped_image\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_plate(plate_img):\n",
    "    print(plate_img.shape)\n",
    "    if (plate_img.shape[1] == 1000):\n",
    "        return []\n",
    "    image_value = cv.split(cv.cvtColor(plate_img, cv.COLOR_BGR2HSV))[2]\n",
    "    \n",
    "    inverted_image = cv.bitwise_not(image_value)\n",
    "    plate_img = imutils.resize(plate_img, width = 200)\n",
    "    inverted_image = imutils.resize(inverted_image, width = 200)\n",
    "    \n",
    "    inverted_image[ inverted_image < 120 ] = 0\n",
    "    inverted_image[ inverted_image >= 120] = 255\n",
    "    \n",
    "    \n",
    "    closeKern = cv.getStructuringElement(cv.MORPH_RECT, (1,4))\n",
    "    inverted_image = cv.dilate(inverted_image,closeKern,iterations=1)\n",
    "    \n",
    "    labels = measure.label(inverted_image, background = 0)\n",
    "    \n",
    " \n",
    "    # show_images([inverted_image])\n",
    "    \n",
    "    # loop over the unique components\n",
    "    black_image = np.zeros(inverted_image.shape, dtype ='uint8')\n",
    "    white_image = np.zeros(inverted_image.shape, dtype ='uint8')\n",
    "    for label in np.unique(labels):\n",
    "    \n",
    "        # if this is the background label, ignore it\n",
    "        if label == 0:\n",
    "            continue\n",
    "        # otherwise, construct the label mask to display\n",
    "        # only connected components for the current label,\n",
    "        # then find contours in the label mask\n",
    "        labelMask = np.zeros(inverted_image.shape, dtype ='uint8')\n",
    "        labelMask[labels == label] = 255     \n",
    "        \n",
    "        \n",
    "        cnts = cv.findContours(labelMask,\n",
    "                    cv.RETR_EXTERNAL,\n",
    "                    cv.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        cnts = cnts[1] if imutils.is_cv3() else cnts[0] # for cv2 and cv3\n",
    "        \n",
    "        #    and solidity < 0.80\n",
    "        \n",
    "        if len(cnts) > 0:\n",
    "                c = max(cnts, key = cv.contourArea)\n",
    "                (boxX, boxY, boxW, boxH) = cv.boundingRect(c)\n",
    "                area = cv.contourArea(c)\n",
    "                heightRatio = boxH / float(plate_img.shape[0])\n",
    "                widthRation = boxW / float(plate_img.shape[1])\n",
    "                aspectRatio = boxW / float(boxH)\n",
    "                solidity = cv.contourArea(c) / float(boxW * boxH)\n",
    "                white_image = cv.bitwise_or(white_image,labelMask)\n",
    "                if(area >=15 and area<600 and heightRatio  <0.9 and widthRation< 0.2 and aspectRatio < 2 and solidity > 0.2 and solidity < 0.8 ):\n",
    "                    black_image = cv.bitwise_or(black_image,labelMask)\n",
    "                \n",
    "                    \n",
    "    # show_images([black_image,white_image])      \n",
    "    morph_kern = cv.getStructuringElement(cv.MORPH_RECT, (1,3))\n",
    "    dilated = cv.dilate(black_image,morph_kern,iterations=2)\n",
    "    show_images([dilated,plate_img])\n",
    "    return [dilated,plate_img]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if two contours intersect\n",
    "def do_contours_intersect(cnt1, cnt2, x_threshold=0):\n",
    "    rect1 = cv.boundingRect(cnt1)\n",
    "    rect2 = cv.boundingRect(cnt2)\n",
    "    x1, y1, w1, h1 = rect1\n",
    "    x2, y2, w2, h2 = rect2\n",
    "\n",
    "    # Check if there is no intersection in the x-direction with the given threshold\n",
    "    if x1 + w1 + x_threshold < x2 or x2 + w2 + x_threshold < x1:\n",
    "        return False\n",
    "\n",
    "    # Check for intersection in the y-direction\n",
    "    return not (y1 + h1 < y2 or y2 + h2 < y1)\n",
    "\n",
    "# Function to merge intersecting contours\n",
    "def merge_intersecting_contours(contours):\n",
    "    merged_contours = []\n",
    "    used = set()\n",
    "\n",
    "    for i, cnt1 in enumerate(contours):\n",
    "        if i not in used:\n",
    "            merged = cnt1.copy()\n",
    "\n",
    "            for j, cnt2 in enumerate(contours):\n",
    "                if i != j and j not in used and do_contours_intersect(cnt1, cnt2):\n",
    "                    merged = np.concatenate((merged, cnt2))\n",
    "                    used.add(j)\n",
    "\n",
    "            merged_contours.append(merged)\n",
    "\n",
    "    return merged_contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = 0\n",
    "car_letters = []\n",
    "def extractChars(img,path):  \n",
    "        if (img == []):\n",
    "            return \n",
    "        filteredCnts = []\n",
    "        closeKern = cv.getStructuringElement(cv.MORPH_RECT, (1,3))\n",
    "        img[0] = cv.dilate(img[0], closeKern, iterations = 1)\n",
    "        \n",
    "        # show_images([img[0],img[1]])\n",
    "        labels = measure.label(img[0], background = 0)\n",
    "        white = img[1].copy()\n",
    "        for idx,label in enumerate(np.unique(labels)):\n",
    "            if label == 0:\n",
    "                continue\n",
    "            # otherwise, construct the label mask to display\n",
    "            # only connected components for the current label,\n",
    "            # then find contours in the label mask\n",
    "            labelMask = np.zeros(img[0].shape, dtype ='uint8')\n",
    "            labelMask[labels == label] = 255\n",
    "\n",
    "            cnts = cv.findContours(labelMask,\n",
    "                    cv.RETR_EXTERNAL,\n",
    "                    cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            cnts = cnts[1] if imutils.is_cv3() else cnts[0] # for cv2 and cv3\n",
    "            # ensure at least one contour was found in the mask\n",
    "            if len(cnts) > 0:\n",
    "\n",
    "                # grab the largest contour which corresponds\n",
    "                # to the component in the mask, then grab the\n",
    "                # bounding box for the contour\n",
    "                c = max(cnts, key = cv.contourArea)\n",
    "                (boxX, boxY, boxW, boxH) = cv.boundingRect(c)\n",
    "\n",
    "                # compute the aspect ratio, solodity, and\n",
    "                # height ration for the component\n",
    "                aspectRatio = boxW / float(boxH)\n",
    "                solidity = cv.contourArea(c) / float(boxW * boxH)\n",
    "                area = cv.contourArea(c)\n",
    "                \n",
    "                # determine if the aspect ratio, solidity,\n",
    "                keepAspectRatio =  aspectRatio < 1\n",
    "\n",
    "                areaRatio =  area > 70 and area < 1100\n",
    "                solidity = cv.contourArea(c) / float(boxW * boxH)\n",
    "                center_line=img[1].shape[0] // 2\n",
    "                \n",
    "                cv.rectangle( white, (boxX, boxY), (boxX + boxW, boxY + boxH), (0, 255, 0), 1)\n",
    "                \n",
    "                # keepAspectRatio  and  \n",
    "                if areaRatio and solidity < 0.8:\n",
    "                    if((center_line > boxY and center_line < boxY+boxH) or (center_line<=boxY) ) :\n",
    "                        # cropped_image = img[1].copy()[boxY:boxY + boxH, boxX:boxX + boxW]\n",
    "                        # removing pole \n",
    "                        filteredCnts.append(c)\n",
    "                        # car_letters.append((cropped_image,boxX))\n",
    "                        # cv.rectangle( img[1], (boxX, boxY), (boxX + boxW, boxY + boxH), (0, 255, 0), 1)\n",
    "                        # cv.putText(img[1], f\"Area: {area}\", (boxX, boxY + boxH + 10), cv.FONT_HERSHEY_SIMPLEX, 0.3, (0, 255, 0), 1)\n",
    "        \n",
    "        \n",
    "        #  can be edited to get better results by merging only the contours which is intersecting in y axis\n",
    "        \n",
    "        filteredCnts = agglomerative_cluster_y(filteredCnts)  \n",
    "        filteredCnts = merge_intersecting_contours(filteredCnts) \n",
    "        for cnt in filteredCnts:\n",
    "            (boxX, boxY, boxW, boxH) = cv.boundingRect(cnt)\n",
    "            cropped_image = img[1].copy()[boxY:boxY + boxH, boxX:boxX + boxW]\n",
    "            car_letters.append((cropped_image,boxX)) \n",
    "            cv.rectangle( img[1], (boxX, boxY), (boxX + boxW, boxY + boxH), (0, 255, 0), 1)\n",
    "        \n",
    "        # merge contoure which is close together in y axis\n",
    "        \n",
    "        \n",
    "        \n",
    "        if (len(car_letters) >= 2 and len(car_letters) <=7):\n",
    "            print(\"valid car\")\n",
    "            flag = 1 \n",
    "        else:\n",
    "            print(\"There is no car\")\n",
    "            flag = 0\n",
    "        \n",
    "        cv.line(img[1], (0,img[1].shape[0]//2), ((img[1].shape[1],img[1].shape[0]//2,)), (255,0,0), 1)\n",
    "        cv.line(white, (0,white.shape[0]//2), ((white.shape[1],white.shape[0]//2,)), (255,0,0), 1)\n",
    "        show_images([img[1],white])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "images = os.listdir('images')\n",
    "for image in images:\n",
    "   extractChars(enhance_plate(LPD(cv.imread('images/'+image))),image)\n",
    "   \n",
    "# LPD(cv.imread('0658.jpg'))\n",
    "# img = cv.imread(\"G.png\")\n",
    "# show_images([img])\n",
    "# extractChars(enhance_plate(LPD(img)),\"0538.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
